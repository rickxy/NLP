{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping & NLP - Central London Data Science Project Nights\n",
    "Instead of relying on excel sheets and database admins to give us the data we need to do our data science, we can take the task into our own hands and collect the data ourselves just by going to webpages.\n",
    "\n",
    "![see the data](images/neo.gif)\n",
    "<p style=\"text-align:center\">Stop seeing web pages and start seeing data.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets see what version of python we are on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great! Python 3! Lets get on with scraping!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "if sys.version_info[0] == 3:\n",
    "    print('Great! Python 3! Lets get on with scraping!')\n",
    "else:\n",
    "    print('Yikes! Python 2! This may not work for you! ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries for doing our scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'requests' is what we use to send web-requests (to fetch the html files from websites)\n",
    "import requests\n",
    "\n",
    "# beautiful-soup will help us in navigating through the html extract just the text we care about\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets decide which page we want to scrap. We'll do https://techcrunch.com/ first. Open the page in your browser (by clicking on the link) to see the visual structure of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEB_PAGE_TO_SCRAPE_URL = \"https://techcrunch.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lets send a web request for a page\n",
    "\n",
    "the code to send a request using the `requests` library is the following:\n",
    "```python\n",
    "    requests.get('http://www.google.com')\n",
    "```\n",
    "send a request to our `WEB_PAGE_TO_SCRAPE_URL` url and store the output in a new variable named `response`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request for the web page\n",
    "# WRITE YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lets look at the text (the html) that was recieved\n",
    "\n",
    "The text from the request response is spored in the `.text` property of the response:\n",
    "\n",
    "```python\n",
    "response_text = response.text\n",
    "\n",
    "```\n",
    "\n",
    "Save the `response.text` to a varible names `fetched_html` and print out the first 500 characters\n",
    "\n",
    "\n",
    "#### If you can reach Techcrunch.com then use the following code to load the html from a file\n",
    "```python\n",
    "fetched_html = ''\n",
    "with open('techcrunch.html', 'r') as f:\n",
    "    fetched_html = f.read()\n",
    "\n",
    "fetched_html[:500]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at some of the raw text (the html), more specificly the first 500 characters \n",
    "# WRITE YOUR CODE HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output of the requuest should look like the following: \n",
    "\n",
    "```html\n",
    "'<!DOCTYPE html>\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:og=\"http://opengraphprotocol.org/schema/\" xmlns:fb=\"http://www.facebook.com/2008/fbml\" lang=\"en\">\\n<head>\\n\\t<title>TechCrunch - The latest technology news and information on startups</title>\\n\\t<meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\\n\\t<meta charset=\"UTF-8\">\\n\\t\\t<meta name=\"p:domain_verify\" content=\"6189ff68ce30e30f12b40b3b40873027\"/>\\n\\t<meta name=\"HandheldFriendly\" content=\"True\">\\n\\t<meta name=\"MobileOptimized\" content=\"320'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confirm that the html does look like the above in your internet browser\n",
    "\n",
    "### *Right click on the web page and click on 'view page source'*\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use BeautifulSoup to parse the html into a searchable python object\n",
    "\n",
    "To be able to extract specific parts of text out of the html we convert it into a python objetc using the `BeautifulSoup` library. To convert raw html into a python object you use the following syntax:\n",
    "\n",
    "```python\n",
    "BeautifulSoup(YOUR_RAW_HTML_TEXT, 'html.parser')\n",
    "```\n",
    "\n",
    "Use the syntax to convert the text from your `response` and assign it to a varible called `souped_page`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Getting specifc elements of the page\n",
    "\n",
    "Within the pages html there is an element that looks like the following:\n",
    "```html\n",
    "<title>TechCrunch - The latest technology news and information on startups</title>\n",
    "```\n",
    "\n",
    "You can find this using `BeautifulSoup` using the following syntax:\n",
    "\n",
    "```python\n",
    "    souped_page.find('title')\n",
    "```\n",
    "\n",
    "This will return the element with the `title` tag (in html the text between < and > is the tag name e.g `<tag name> random text </tag name>`).\n",
    "\n",
    "Find the title element in our converted page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your output should look like:\n",
    "```html\n",
    "<title>TechCrunch - The latest technology news and information on startups</title>\n",
    "```\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract the text from an element\n",
    "You can extract the actual text of an element by just calling `.getText()` on the element. \n",
    "\n",
    "Try extracting just the text from the `title` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your output should look like:\n",
    "```python\n",
    "'TechCrunch - The latest technology news and information on startups'\n",
    "```\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. More advanced element extraction\n",
    "If your having an easy life all you'll need to do is extract a single element that has a unique tag name i.e what we just did previously. **BUT** that will rarely be the case. If you looked at the raw html you would have seen a lot of tags called `div`. \n",
    "\n",
    "`div` are a very common tag that are used becuase they are pretty generic i.e they are the blank slate of html elements. Web developers use them a lot becuase they can easily modify them using additional html attributes like n the following code:\n",
    "\n",
    "\n",
    "### Here is a bog standard `div` and won't do anything special\n",
    "<img src=\"images/element_without_attributes.png\" style=\"width: 600px; margin-left: 0;\"/>\n",
    "\n",
    "\n",
    "\n",
    "### Here is a `div` that has additional attributes that will change the way it looks in the browser\n",
    "<img src=\"images/element_with_attributes.png\" style=\"width: 600px; margin-left: 0;\"/>\n",
    "\n",
    "\n",
    "\n",
    "### In the following section we will look at how you can search for elements based on their tag and their attributes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Use your browsers 'inspect' to help find the element you want to scrape\n",
    "\n",
    "Most modern browsers allow you to find the exact code for the part of the webpage you are looking at.\n",
    "\n",
    "In chrome: right click on the part of the page and click  ***'inspect'***\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"images/inspect.png\" style=\"border: red solid 2px;\" />\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "### Chrome will highlight the related part of the webpage as you move your mouse over the code\n",
    "\n",
    "<img src=\"images/element_find.png\" style=\"border: red solid 2px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup query syntax\n",
    "\n",
    "Take a look at some html that we've fetched from techcrunch.com\n",
    "\n",
    "<img src=\"images/bs_syntax.png\" style=\"width: 600px; margin-left: 0;\"/>\n",
    "\n",
    "Using beautiful-soup we could try to find this element by looking for the tag:\n",
    "```python\n",
    "souped_page.find('ul')\n",
    "```\n",
    "Try to find the `ul` element by running `souped_page.find('ul')`:\n",
    "\n",
    "**NOTE** : *Dont worry if the output looks long - it prints out the element along with all of its nested elements*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## That isn't our element!\n",
    "The element we wanted looked like:\n",
    "```html\n",
    "<ul class=\"river lc-padding\" id=\"river1\">\n",
    "```\n",
    "Instead we got:\n",
    "```html\n",
    "<ul class=\"inline-list social-list sprite-social\">\n",
    "```\n",
    "\n",
    "**The problem** is that there are loads of `ul` elements on this page (fyi `ul` means 'unordered-list').\n",
    "\n",
    "We need to be more specific, we can search for elements based both on the tag and element attributes like so:\n",
    "```python\n",
    "# pass in a dictionary of the attributes you want to search for\n",
    "souped_page.find('ul', {'class':'river'})\n",
    "```\n",
    "Try to find the `ul` element using the `.find('ul', {'class':'river'})` command on our `souped_page` adn asign the out to varible called `element_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'element_search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9e056fe7ba8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# let's just see if all of the attributes match\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0melement_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'element_search' is not defined"
     ]
    }
   ],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "# I won't print it all becuase it's quite long\n",
    "# let's just see if all of the attributes match\n",
    "\n",
    "element_search.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your output should look like:\n",
    "```python\n",
    "{'class': ['river', 'lc-padding'], 'id': 'river1'}\n",
    "```\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Getting a list of elements\n",
    "up until this point we have been using the `.find` command which returns the first match to our search.\n",
    "\n",
    "We can get all matches by using the `.find_all` command instead.\n",
    "\n",
    "This will return a list of all of the matching elements.\n",
    "\n",
    "On the techcruch home page each article is a `li` tag (li stands for list item) with a `class` attribute that is `'river-block '`\n",
    "\n",
    "Do a `.find_all` for these elements and asign the output to a varible called `article_listings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_listings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-89b894ae78e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# YOUR CODE ENDS HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Numer of article:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_listings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Printing article titles \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'article_listings' is not defined"
     ]
    }
   ],
   "source": [
    "# YOUR CODE STARTS HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "print('Numer of article:', len(article_listings))\n",
    "print('Printing article titles \\n')\n",
    "\n",
    "# we know most of these elements has an attribute called 'data-sharetitle' that stores the articles title\n",
    "# so lets print these out\n",
    "\n",
    "for a in article_listings:\n",
    "    if 'data-sharetitle' in a.attrs:\n",
    "        print(a['data-sharetitle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Your task -  Scrape an article\n",
    "\n",
    "There is an article at 'https://techcrunch.com/2018/02/25/gobee-bike-throws-in-the-towel-on-france/'.\n",
    "\n",
    "Your tasked with scraping just the article text i.e the text in the red box. \n",
    "\n",
    "Save the scraped text in a varible named `article_text`\n",
    "\n",
    "\n",
    "<img src=\"images/page_to_scrape.png\" />\n",
    "\n",
    "\n",
    "# GO!\n",
    "\n",
    "## **NOTE**: *If you get stuck look at the completed notebook *\n",
    "\n",
    "#### IF YOU CANT REACH TECHCRUNCH.COM USE THE FOLLOWING CODE TO GET THE HTML FROM FILE\n",
    "```python\n",
    "backup_article = ''\n",
    "with open('techcrunch_article.html', 'r') as f:\n",
    "    backup_article = f.read()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE (MAKE AS MANY NEW CELLS AS YOU LIKE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your output should look like:\n",
    "```python\n",
    "'   Bike-sharing startup GoBee Bike is giving up and shutting down in all French cities where it operates. GoBee Bike operates just like Chinese giants Ofo and Mobike. You open  the app, you find a bike on the map and you unlock it by scanning a QR code. Once you’re done, you lock it again and leave it there — there’s no dock. And yet, the startup is blaming vandalism and says that the service would stop immediately. It’s worth noting that users will get a refund on their remaining balances and €15 deposit. This is a nice gesture. According to the announcement, GoBee Bike managed to attract 150,000 users in Europe who used the service hundreds of thousands of times. But the company’s bikes slowly became unusable. 3,200 bikes became dysfunctional, 1,000 bikes were illegally parked in someone’s home. Overall, GoBee Bike had to send someone in 6,500 cases. The startup couldn’t keep up and it became clear that the business model wasn’t scalable if you needed to fix the bikes all the time. As a user, it also felt like you couldn’t unlock most of the bikes because the lock battery was dead most of the time. GoBee Bike first announced that it would stop operating in Brussels, Lille and Reims. The startup also exited the Italian market. And now, users in Paris and Lyon can’t access the service either. The company is still operating in its home city Hong Kong. In Paris in particular, there were four different free-floating bike companies — Ofo, Mobike, Obike and GoBee Bike. GoBee Bike is clearly underfunded compared to those giants. According to CrunchBase, GoBee Bike has raised $9 million. Ofo and Mobike have raised over $2 billion combined. And you can feel it as a user. While Ofo has been operating in Paris since mid-December, all rides have been free for the past two and half months. Mobike has been around for a month and rides are free as well. Even Obike gave you 50 free rides when you signed up. It’s hard to compete with free.  '\n",
    "```\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align:center\">Now you should see all of the internet as scrapable data </h1>\n",
    "![new view](images/matrix.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do some NLP now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textblob has a pre-trained sentiment analysis model that we can use\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using TextBlob to get sentiment scores\n",
    "\n",
    "Textblob makes it very easy to get sentiment scores form text. \n",
    "\n",
    "We use the following code to convert text into a TextBlob obejct:\n",
    "\n",
    "```python\n",
    "my_text_blob_object = TextBlob('This is some test text')\n",
    "\n",
    "```\n",
    "\n",
    "The sentiment scores are stored as a `.sentiment` property on the TextBlob object:\n",
    "\n",
    "```python\n",
    "my_text_blob_object.sentiment\n",
    "```\n",
    "\n",
    "This will return a value pair representing the sentiment scores for the text.\n",
    "\n",
    "Here is a section of the TextBlob documentation that explains what the values in the value pair mean:\n",
    "\n",
    "From https://textblob.readthedocs.io/en/dev/api_reference.html#textblob.blob.TextBlob.sentiment\n",
    "\n",
    "> TextBlob.sentiment\n",
    "\n",
    "> Return a tuple(value pair) of form `(polarity, subjectivity )` where polarity is a float(number) within the range `[-1.0, 1.0]` and subjectivity is a float(number) within the range `[0.0, 1.0]` where 0.0 is very objective and 1.0 is very subjective.\n",
    "\n",
    "### Your task\n",
    "\n",
    "Create a TextBlob object using your `article_text` that you scraped and print out out the sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your output should look like (may not be exact):\n",
    "\n",
    "Sentiment(polarity=0.09011111111111111, subjectivity=0.41522222222222227)\n",
    "<br/>\n",
    "<br/>\n",
    "What these scores say is that the text is fairly subjective (opinionated) but very neutral in polarity (not phrased in a negative or positive way)\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What are the more subjective (emotional) sentences?\n",
    "\n",
    "We have just gotten the sentiment scores for the whole text, but we can split up teh text and analyse the sentiment of each sentence.\n",
    "\n",
    "```python\n",
    "# split up text into sentences\n",
    "sentences = article_text.split('.')\n",
    "\n",
    "# loop for each sentence\n",
    "for sentence in sentences:\n",
    "    \n",
    "    # get sentiment score for sentence\n",
    "    sentence_sentiment = TextBlob(sentence).sentiment\n",
    "    \n",
    "    # if the subjectivity(opinionated) score is greater than 0.5 then \n",
    "    # print out the sentence with the score    \n",
    "    if  sentence_sentiment.subjectivity > 0.5:\n",
    "        print(sentence, sentence_sentiment.subjectivity)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR CODE HERE OR COPY AND PASTED FROM ABOVE\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your output should look like (may not be exact):\n",
    "\n",
    "This is a nice gesture 1.0\n",
    "Mobike has been around for a month and rides are free as well 0.8\n",
    "Even Obike gave you 50 free rides when you signed up 0.8\n",
    "It’s hard to compete with free 0.6708333333333334\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced sentiment ploting - Can we plot the words by their sentiment? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ploting library \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# draw plot in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-11395c0d0dd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get all word indevidually by splitting on every space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marticle_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# big it a big plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'article_text' is not defined"
     ]
    }
   ],
   "source": [
    "# get all word indevidually by splitting on every space\n",
    "words = article_text.split(' ')\n",
    "\n",
    "# big it a big plot\n",
    "plt.figure(figsize=(12,7))\n",
    "\n",
    "# for each word draw the text on teh char using the sentiment score as the x and y coordinates\n",
    "for word in words:\n",
    "    word_sentiment = TextBlob(word).sentiment\n",
    "    plt.text(word_sentiment.polarity, # x coordinate\n",
    "             word_sentiment.subjectivity, # y coordinate\n",
    "             word) # the text to draw\n",
    "\n",
    "# set axis ranges \n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "# draw line in middle\n",
    "plt.axvline(0, color='red', linestyle='dashed')\n",
    "\n",
    "# label axis\n",
    "plt.title('Sentiment analysis of words')\n",
    "plt.xlabel('Polarity (positive(love) or negative(hate))')\n",
    "plt.ylabel('Subjectivity (0 - purly objective, 1 - purly subjective)')\n",
    "\n",
    "# display\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats on getting through everything! now go and scrape!\n",
    "![fly](images/neo_flying.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
